[2025-08-02 16:57:27,278: INFO: main: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-02 16:57:27,286: ERROR: main: main: expected str, bytes or os.PathLike object, not NoneType]
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 14, in <module>
    data_ingestion.initiate_data_ingestion()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion.py", line 14, in initiate_data_ingestion
    data_ingestion_config = config.get_data_ingestion_config()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 28, in get_data_ingestion_config
    unzip_dir=Path(config['unzip_dir'])
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\venv\lib\pathlib.py", line 958, in __new__
    self = cls._from_parts(args)
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\venv\lib\pathlib.py", line 592, in _from_parts
    drv, root, parts = self._parse_args(args)
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\venv\lib\pathlib.py", line 576, in _parse_args
    a = os.fspath(a)
TypeError: expected str, bytes or os.PathLike object, not NoneType
[2025-08-02 17:03:38,580: INFO: main: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-02 17:03:39,273: INFO: data_ingestion: data_ingestion: artifacts\data_ingestion\iris.csv downloaded! Info: 
Connection: close
Content-Length: 3858
Cache-Control: max-age=300
Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox
Content-Type: text/plain; charset=utf-8
ETag: "d1ae283e9a4cd53de5e784edb7fee7b363ca06aef5b946c9fa0574f27d58e2c8"
Strict-Transport-Security: max-age=31536000
X-Content-Type-Options: nosniff
X-Frame-Options: deny
X-XSS-Protection: 1; mode=block
X-GitHub-Request-Id: F54B:251B1E:135DDD:330C79:688DF792
Accept-Ranges: bytes
Date: Sat, 02 Aug 2025 11:33:38 GMT
Via: 1.1 varnish
X-Served-By: cache-maa10227-MAA
X-Cache: MISS
X-Cache-Hits: 0
X-Timer: S1754134418.450731,VS0,VE253
Vary: Authorization,Accept-Encoding
Access-Control-Allow-Origin: *
Cross-Origin-Resource-Policy: cross-origin
X-Fastly-Request-ID: d6f56f03da1a23400aadce4b76fc924917576c80
Expires: Sat, 02 Aug 2025 11:38:38 GMT
Source-Age: 0

]
[2025-08-02 17:03:39,275: INFO: data_ingestion: data_ingestion: Skipping extraction as unzip_dir is not set.]
[2025-08-02 17:03:39,276: INFO: main: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-02 21:20:12,894: INFO: main: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-02 21:20:12,905: INFO: data_ingestion: data_ingestion: File already exists at: artifacts\data_ingestion\iris.csv]
[2025-08-02 21:20:12,905: INFO: data_ingestion: data_ingestion: Skipping extraction as unzip_dir is not set.]
[2025-08-02 21:20:12,905: INFO: main: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 17:23:14,825: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 17:23:14,848: ERROR: main: 'dict' object has no attribute 'data_validation']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 15, in <module>
    data_ingestion.initiate_data_ingestion()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion_pipeline.py", line 13, in initiate_data_ingestion
    config = ConfigurationManager()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 15, in __init__
    os.makedirs(self.config.data_validation.root_dir, exist_ok=True)
AttributeError: 'dict' object has no attribute 'data_validation'
[2025-08-03 17:24:45,289: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 17:24:45,293: ERROR: main: 'dict' object has no attribute 'data_validation']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 14, in <module>
    data_ingestion.initiate_data_ingestion()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion_pipeline.py", line 13, in initiate_data_ingestion
    config = ConfigurationManager()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 15, in __init__
    os.makedirs(self.config.data_validation.root_dir, exist_ok=True)
AttributeError: 'dict' object has no attribute 'data_validation'
[2025-08-03 17:27:53,827: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 17:27:53,830: ERROR: main: DataIngestionConfig.__init__() got an unexpected keyword argument 'source_URL']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 14, in <module>
    data_ingestion.initiate_data_ingestion()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion_pipeline.py", line 14, in initiate_data_ingestion
    data_ingestion_config = config.get_data_ingestion_config()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 21, in get_data_ingestion_config
    return DataIngestionConfig(
TypeError: DataIngestionConfig.__init__() got an unexpected keyword argument 'source_URL'
[2025-08-03 17:31:00,268: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 17:31:00,273: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 17:31:00,273: INFO: data_ingestion: Skipping extraction as unzip_dir is not set.]
[2025-08-03 17:31:00,273: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 17:31:00,273: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 17:31:00,274: ERROR: main: 'DataValidationTrainingPipeline' object has no attribute 'run_validation']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 30, in <module>
    data_validation.run_validation()
AttributeError: 'DataValidationTrainingPipeline' object has no attribute 'run_validation'
[2025-08-03 17:47:28,095: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 17:47:28,100: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 17:47:28,101: INFO: data_ingestion: Skipping extraction as unzip_dir is not set.]
[2025-08-03 17:47:28,101: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 17:47:28,101: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 17:47:28,101: ERROR: main: 'DataValidationTrainingPipeline' object has no attribute 'run_validation']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 30, in <module>
    data_validation.run_validation()
AttributeError: 'DataValidationTrainingPipeline' object has no attribute 'run_validation'
[2025-08-03 18:14:08,580: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 18:14:08,590: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 18:14:08,591: INFO: data_ingestion: Skipping extraction as unzip_dir is not set.]
[2025-08-03 18:14:08,592: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 18:14:08,594: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 18:14:08,595: ERROR: main: 'DataValidationTrainingPipeline' object has no attribute 'run_validation']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 30, in <module>
    data_validation.run_validation()
AttributeError: 'DataValidationTrainingPipeline' object has no attribute 'run_validation'
[2025-08-03 18:17:11,962: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 18:17:11,979: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 18:17:11,979: INFO: data_ingestion: Skipping extraction as unzip_dir is not set.]
[2025-08-03 18:17:11,980: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 18:17:11,980: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 18:17:11,981: ERROR: main: 'DataValidationTrainingPipeline' object has no attribute 'run_validation']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 28, in <module>
    data_validation.run_validation()
AttributeError: 'DataValidationTrainingPipeline' object has no attribute 'run_validation'
[2025-08-03 18:21:28,490: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 18:21:28,494: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 18:21:28,504: INFO: data_ingestion: Skipping extraction as unzip_dir is not set.]
[2025-08-03 18:21:28,506: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 18:21:28,507: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 18:21:28,510: ERROR: main: 'DataValidationTrainingPipeline' object has no attribute 'run_validation']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 28, in <module>
    data_validation.run_validation()
AttributeError: 'DataValidationTrainingPipeline' object has no attribute 'run_validation'
[2025-08-03 18:24:05,157: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 18:24:05,166: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 18:24:05,167: INFO: data_ingestion: Skipping extraction as unzip_dir is not set.]
[2025-08-03 18:24:05,168: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 18:24:05,168: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 18:27:30,177: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 18:27:30,186: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 18:27:30,186: INFO: data_ingestion: Skipping extraction as unzip_dir is not set.]
[2025-08-03 18:27:30,187: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 18:27:30,188: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 18:57:20,179: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 18:57:20,188: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 18:57:20,189: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 18:57:20,190: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 18:57:20,197: ERROR: main: DataValidationConfig.__init__() got an unexpected keyword argument 'unzip_data_path']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 27, in <module>
    data_validation.initiate_data_validation()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_validation_pipeline.py", line 13, in initiate_data_validation
    data_validation_config = config.get_data_validation_config()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 32, in get_data_validation_config
    return DataValidationConfig(
TypeError: DataValidationConfig.__init__() got an unexpected keyword argument 'unzip_data_path'
[2025-08-03 19:05:23,999: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 19:05:24,009: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 19:05:24,010: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 19:05:24,012: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 19:09:52,130: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 19:09:52,140: INFO: data_ingestion: File already exists at: artifacts/data_ingestion/iris.csv]
[2025-08-03 19:09:52,141: INFO: main: >>>>>>> Stage Data Ingestion Stage completed <<<<<<<<

x==========x]
[2025-08-03 19:09:52,141: INFO: main: >>>>>>> Stage Data Validation Stage started <<<<<<<<]
[2025-08-03 19:09:52,153: ERROR: main: 'local_data_file']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 27, in <module>
    data_validation.initiate_data_validation()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_validation_pipeline.py", line 13, in initiate_data_validation
    data_validation_config = config.get_data_validation_config()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 33, in get_data_validation_config
    local_data_file=config["local_data_file"],
KeyError: 'local_data_file'
[2025-08-03 19:18:18,770: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 19:18:18,779: ERROR: main: DataIngestionConfig.__init__() got an unexpected keyword argument 'unzip_dir']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 13, in <module>
    data_ingestion.initiate_data_ingestion()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion_pipeline.py", line 13, in initiate_data_ingestion
    data_ingestion_config = config.get_data_ingestion_config()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 21, in get_data_ingestion_config
    return DataIngestionConfig(
TypeError: DataIngestionConfig.__init__() got an unexpected keyword argument 'unzip_dir'
[2025-08-03 19:19:37,096: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 19:19:37,101: ERROR: main: [Errno 2] No such file or directory: 'config\\schema.yaml']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 13, in <module>
    data_ingestion.initiate_data_ingestion()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion_pipeline.py", line 12, in initiate_data_ingestion
    config = ConfigurationManager()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 13, in __init__
    self.schema = read_yaml(schema_file_path)
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\utils\common.py", line 8, in read_yaml
    with open(path_to_yaml, 'r') as yaml_file:
FileNotFoundError: [Errno 2] No such file or directory: 'config\\schema.yaml'
[2025-08-03 19:22:50,765: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 19:22:50,772: ERROR: main: [Errno 2] No such file or directory: 'config\\schema.yaml']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 13, in <module>
    data_ingestion.initiate_data_ingestion()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion_pipeline.py", line 12, in initiate_data_ingestion
    config = ConfigurationManager()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 13, in __init__
    self.schema = read_yaml(schema_file_path)
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\utils\common.py", line 8, in read_yaml
    with open(path_to_yaml, 'r') as yaml_file:
FileNotFoundError: [Errno 2] No such file or directory: 'config\\schema.yaml'
[2025-08-03 19:26:33,609: INFO: utils: Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.]
[2025-08-03 19:26:33,611: INFO: utils: NumExpr defaulting to 8 threads.]
[2025-08-03 19:26:34,568: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 19:26:34,572: ERROR: main: [Errno 2] No such file or directory: 'config\\schema.yaml']
Traceback (most recent call last):
  File "c:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 13, in <module>
    data_ingestion.initiate_data_ingestion()
  File "c:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion_pipeline.py", line 12, in initiate_data_ingestion
    config = ConfigurationManager()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 13, in __init__
    self.schema = read_yaml(schema_file_path)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\utils\common.py", line 8, in read_yaml
    with open(path_to_yaml, 'r') as yaml_file:
         ^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'config\\schema.yaml'
[2025-08-03 19:27:19,540: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 19:27:19,540: ERROR: main: [Errno 2] No such file or directory: 'config\\schema.yaml']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 13, in <module>
    data_ingestion.initiate_data_ingestion()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion_pipeline.py", line 12, in initiate_data_ingestion
    config = ConfigurationManager()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 13, in __init__
    self.schema = read_yaml(schema_file_path)
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\utils\common.py", line 8, in read_yaml
    with open(path_to_yaml, 'r') as yaml_file:
FileNotFoundError: [Errno 2] No such file or directory: 'config\\schema.yaml'
[2025-08-03 19:28:16,841: INFO: main: >>>>>>> Stage Data Ingestion Stage started <<<<<<<<]
[2025-08-03 19:28:16,841: ERROR: main: [Errno 2] No such file or directory: 'config\\schema.yaml']
Traceback (most recent call last):
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\main.py", line 13, in <module>
    data_ingestion.initiate_data_ingestion()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\pipeline\data_ingestion_pipeline.py", line 12, in initiate_data_ingestion
    config = ConfigurationManager()
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\config\configuration.py", line 13, in __init__
    self.schema = read_yaml(schema_file_path)
  File "C:\Users\hr591\OneDrive\Desktop\DatascienceProject\src\datascienceproject\utils\common.py", line 8, in read_yaml
    with open(path_to_yaml, 'r') as yaml_file:
FileNotFoundError: [Errno 2] No such file or directory: 'config\\schema.yaml'
